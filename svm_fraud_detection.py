# -*- coding: utf-8 -*-
"""svm_fraud_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M0BDAegwXM90IE6o9wSlYu9Oj1EvSAh4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


#Scaling the amount feature
from sklearn.preprocessing import StandardScaler

#To evalute the model
from sklearn import metrics
from sklearn.metrics import confusion_matrix

#Import libraries
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix


#models
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("/content/creditcard.csv")

df.shape

df.head()

df.isnull().sum()

df.describe()

df.info()

class_dis = df["Class"].value_counts()
class_dis

fraud_cases = df[df['Class'] == 1]
safe_cases = df[df['Class'] == 0]
print('The number of fraud transactions are {}'.format(fraud_cases.shape[0]))
print('The number of safe transactions are {}'.format(safe_cases.shape[0]))

class_dis.plot(kind = "pie", autopct= "%1.1f%%", figsize =(8,4))
plt.legend()
plt.title("The distribution of Safe and Fraudulant transaction ")

#Adjust this to to fit just the SVM model
scaler = StandardScaler()
df['Amount'] = scaler.fit_transform(df[['Amount']])

X = df.drop('Class', axis = 1).values
y = df['Class'].values

from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, RandomizedSearchCV
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 50)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""#Decision Tree Model"""

#fit model to train data set and make predictions
model = DecisionTreeClassifier(criterion = "gini", max_depth = 5, random_state = 33 )
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

#Score
train_score = model.score(X_train, y_train )
test_score = model.score(X_test, y_test)

print(f"The train score is {train_score}.\n The test score is {test_score} ")

#Confusion Matrix
cm_model = confusion_matrix(y_test, y_pred)

cm_dataframe = pd.DataFrame(cm_model)

sns.heatmap(cm_dataframe, annot=True, cbar=None, cmap="Blues", fmt = 'g')
plt.title("Decision Tree Confusion Matrix"), plt.tight_layout()
plt.ylabel("True Class"), plt.xlabel("Predicted Class")
plt.show()

"""#Random Fores Model"""

#fit and predict

random_forest_model = RandomForestClassifier(criterion = "gini",n_estimators = 200, max_depth = 5, random_state = 33, n_jobs =-1)
random_forest_model.fit(X_test, y_test)
y_pred_rf = random_forest_model.predict(X_test)

#Scoring
train_score_rf = random_forest_model.score(X_train, y_train)
test_score_rf = random_forest_model.score(X_test, y_test )

print(f"This is the train score {train_score_rf}.\n This is the test score {test_score_rf} ")

#Confusion Matrix
cm_model_rf = confusion_matrix ( y_test, y_pred_rf)
cm_dataframe_rf = pd.DataFrame (cm_model_rf)


sns.heatmap(cm_dataframe_rf, annot=True, cbar=None, cmap="Greens", fmt = 'g')
plt.title("Random Forest Confusion Matrix"), plt.tight_layout()
plt.ylabel("True Class"), plt.xlabel("Predicted Class")
plt.show()

models = pd.DataFrame({ "Model": ["Decision Tree", "Random Forest"],
                       "Train Score": [train_score, train_score_rf],
                        "Test Score": [test_score, test_score_rf]
                        })

models.sort_values(["Train Score", "Test Score"], ascending =
                   [False, False])

fig, ax = plt.subplots(2, 2,figsize=(20,15))
fig.tight_layout(pad=10.0)
sns.set(font_scale=2)


sns.heatmap(cm_model, ax=ax[1][0], annot=True, cbar=None, cmap="Blues", fmt = 'g')
ax[1][0].set_title("Decision Tree", fontsize=18)
ax[1][0].set_ylabel("True Class"), ax[1][0].set_xlabel("Predicted Class")


sns.heatmap(cm_model_rf, ax=ax[1][1], annot=True, cbar=None, cmap="Greens", fmt = 'g')
ax[1][1].set_title("Random Forest", fontsize=18),
ax[1][1].set_ylabel("True Class"), ax[1][1].set_xlabel("Predicted Class")

plt.show()

"""#SVM Model"""

linear_model = SVC(kernel = "linear")
linear_model.fit(X_train, y_train)

y_pred = linear_model.predict(X_test)

print("accuracy", metrics.accuracy_score(y_true= y_test, y_pred = y_pred),"\n")

print(metrics.confusion_matrix(y_true = y_test, y_pred = y_pred))

#Trying a NON-Linear

non_linear_model = SVC(kernel = "rbf")
non_linear_model.fit(X_train, y_train)

y_pred2 = non_linear_model.predict(X_test)

print(metrics.accuracy_score(y_true = y_test, y_pred = y_pred2 ))

print(metrics.confusion_matrix(y_true = y_test, y_pred = y_pred2))

#Adjusting the Hyperparameter

folds = KFold(n_splits = 5, shuffle = True, random_state = 10)

hyper_params = [{"gamma": [1e-2, 1e-3, 1e-4],
                 "C":[5,10]}]

model = SVC(kernel = "rbf")

model_cv = GridSearchCV(estimator = model,
                        param_grid = hyper_params,
                        cv = folds,
                        verbose = 1,
                        return_train_score = True)

model_cv.fit(X_train, y_train)

cv_results = pd.DataFrame(model_cv.cv_results_)
cv_results

# converting C to numeric type for plotting on x-axis
cv_results['param_C'] = cv_results['param_C'].astype('int')

# # plotting
plt.figure(figsize=(16,8))

# subplot 1/3
plt.subplot(131)
gamma_01 = cv_results[cv_results['param_gamma']==0.01]

plt.plot(gamma_01["param_C"], gamma_01["mean_test_score"])
plt.plot(gamma_01["param_C"], gamma_01["mean_train_score"])
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title("Gamma=0.01")
plt.ylim([0.60, 1])
plt.legend(['test accuracy', 'train accuracy'], loc='upper left')
plt.xscale('log')


# subplot 2/3
plt.subplot(132)
gamma_001 = cv_results[cv_results['param_gamma']==0.001]

plt.plot(gamma_001["param_C"], gamma_001["mean_test_score"])
plt.plot(gamma_001["param_C"], gamma_001["mean_train_score"])
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title("Gamma=0.001")
plt.ylim([0.60, 1])
plt.legend(['test accuracy', 'train accuracy'], loc='upper left')
plt.xscale('log')


# subplot 3/3
plt.subplot(133)
gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]

plt.plot(gamma_0001["param_C"], gamma_0001["mean_test_score"])
plt.plot(gamma_0001["param_C"], gamma_0001["mean_train_score"])
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title("Gamma=0.0001")
plt.ylim([0.60, 1])
plt.legend(['test accuracy', 'train accuracy'], loc='upper left')
plt.xscale('log')

